{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "\n",
    "def make_json(csvFilePath, jsonFilePath):\n",
    "\n",
    "    # create a dictionary\n",
    "    data = {}\n",
    "\n",
    "    # Open a csv reader called DictReader\n",
    "    with open(csvFilePath, encoding=\"utf-8\") as csvf:\n",
    "        csvReader = csv.DictReader(csvf)\n",
    "\n",
    "        # Convert each row into a dictionary\n",
    "        # and add it to data\n",
    "        for rows in csvReader:\n",
    "\n",
    "            key = rows[\"metadataid\"]\n",
    "            data[key] = rows\n",
    "\n",
    "    # Open a json writer, and use the json.dumps()\n",
    "    # function to dump data\n",
    "    with open(jsonFilePath, \"w\", encoding=\"utf-8\") as jsonf:\n",
    "        jsonf.write(json.dumps(data, indent=4))\n",
    "\n",
    "\n",
    "# Driver Code\n",
    "\n",
    "# Decide the two file paths according to your\n",
    "# computer system\n",
    "csvFilePath = r\"./metadata_category_clothing_shoes_and_jewelry_only.csv\"\n",
    "jsonFilePath = r\"./metadata.json\"\n",
    "\n",
    "# Call the make_json function\n",
    "make_json(csvFilePath, jsonFilePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import ast  # To safely convert string representations of dictionaries/lists\n",
    "\n",
    "\n",
    "def convert_value(value):\n",
    "    \"\"\"Try to convert a string into a dictionary, list, number, or keep it as a string.\"\"\"\n",
    "    value = value.strip()  # Remove leading/trailing spaces\n",
    "\n",
    "    # Skip conversion if the value is empty\n",
    "    if not value:\n",
    "        return value\n",
    "\n",
    "    # Try JSON parsing first\n",
    "    try:\n",
    "        return json.loads(value)  # Works for dicts, lists, numbers, booleans, and null\n",
    "    except (json.JSONDecodeError, TypeError):\n",
    "        pass  # If it fails, move to the next step\n",
    "\n",
    "    # Try converting to a number (int or float)\n",
    "    if value.replace(\".\", \"\", 1).isdigit():\n",
    "        return float(value) if \".\" in value else int(value)\n",
    "\n",
    "    return value  # Keep as a string if nothing works\n",
    "\n",
    "\n",
    "def make_json(csvFilePath, jsonFilePath):\n",
    "    \"\"\"Convert a CSV file to JSON, ensuring proper data types.\"\"\"\n",
    "    data = []\n",
    "\n",
    "    with open(csvFilePath, encoding=\"utf-8\") as csvf:\n",
    "        csvReader = csv.DictReader(csvf)\n",
    "\n",
    "        for row in csvReader:\n",
    "            # Convert all columns dynamically\n",
    "            row = {key: convert_value(value) for key, value in row.items()}\n",
    "            data.append(row)\n",
    "\n",
    "    with open(jsonFilePath, \"w\", encoding=\"utf-8\") as jsonf:\n",
    "        json.dump(data, jsonf, indent=4)\n",
    "\n",
    "\n",
    "# Paths\n",
    "csvFilePath = r\"./reviews_Clothing_Shoes_and_Jewelry_5.csv\"\n",
    "jsonFilePath = r\"./reviews.json\"\n",
    "\n",
    "# Convert\n",
    "make_json(csvFilePath, jsonFilePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import psycopg2\n",
    "import io\n",
    "import json\n",
    "from datetime import datetime\n",
    "from itertools import islice\n",
    "\n",
    "# Database connection settings\n",
    "DB_STAGE1 = {\n",
    "    \"dbname\": \"your_db\",\n",
    "    \"user\": \"your_user\",\n",
    "    \"password\": \"your_password\",\n",
    "    \"host\": \"your_host\",\n",
    "    \"port\": \"your_port\",\n",
    "}\n",
    "\n",
    "# Max lengths for columns (based on your table definition)\n",
    "MAX_LENGTHS = {\n",
    "    \"R_Reviewer_Source_Key\": 14,\n",
    "    \"R_Product_Key\": 10,\n",
    "    \"R_Reviewer_Name\": 100,\n",
    "    \"R_Review_Text\": 225,\n",
    "    \"R_Review_Title\": 150,\n",
    "    \"R_Review_DateTime\": 19,  # Timestamp format length (yyyy-mm-dd hh:mm:ss)\n",
    "}\n",
    "\n",
    "\n",
    "def ingest_reviews(csvFilePath):\n",
    "    chunk_size = 1000  # Process in chunks of 1000\n",
    "    chunk_count = 0  # Track chunks\n",
    "\n",
    "    failed_rows = []  # To collect failed rows for logging to JSON\n",
    "\n",
    "    with open(csvFilePath, encoding=\"utf-8\") as csvf, psycopg2.connect(\n",
    "        **DB_STAGE1\n",
    "    ) as conn:\n",
    "\n",
    "        cursor = conn.cursor()\n",
    "        csvReader = csv.DictReader(csvf)\n",
    "\n",
    "        while True:\n",
    "            chunk = list(islice(csvReader, chunk_size))  # Read 1000 rows at a time\n",
    "            if not chunk:\n",
    "                break  # Stop when no more data\n",
    "\n",
    "            transformed_rows = []\n",
    "            for row in chunk:\n",
    "                try:\n",
    "                    # Extract and transform data\n",
    "                    reviewer_id = str(row[\"reviewerID\"])\n",
    "                    product_key = str(row[\"asin\"])\n",
    "                    reviewer_name = (\n",
    "                        str(row[\"reviewerName\"])\n",
    "                        if row[\"reviewerName\"]\n",
    "                        else \"*Unknown Username\"\n",
    "                    )\n",
    "\n",
    "                    # Validate string lengths\n",
    "                    if len(reviewer_id) > MAX_LENGTHS[\"R_Reviewer_Source_Key\"]:\n",
    "                        failed_rows.append(\n",
    "                            {\"row\": row, \"error\": \"reviewer_id too long\"}\n",
    "                        )\n",
    "                        continue\n",
    "                    if len(product_key) > MAX_LENGTHS[\"R_Product_Key\"]:\n",
    "                        failed_rows.append(\n",
    "                            {\"row\": row, \"error\": \"product_key too long\"}\n",
    "                        )\n",
    "                        continue\n",
    "                    if len(reviewer_name) > MAX_LENGTHS[\"R_Reviewer_Name\"]:\n",
    "                        failed_rows.append(\n",
    "                            {\"row\": row, \"error\": \"reviewer_name too long\"}\n",
    "                        )\n",
    "                        continue\n",
    "\n",
    "                    review_text = (\n",
    "                        str(row[\"reviewText\"])\n",
    "                        if row[\"reviewText\"]\n",
    "                        else \"*Unknown review text\"\n",
    "                    )\n",
    "                    if len(review_text) > MAX_LENGTHS[\"R_Review_Text\"]:\n",
    "                        failed_rows.append(\n",
    "                            {\"row\": row, \"error\": \"review_text too long\"}\n",
    "                        )\n",
    "                        continue\n",
    "\n",
    "                    review_title = (\n",
    "                        str(row[\"summary\"])\n",
    "                        if row[\"summary\"]\n",
    "                        else \"*Unknown review title\"\n",
    "                    )\n",
    "                    if len(review_title) > MAX_LENGTHS[\"R_Review_Title\"]:\n",
    "                        failed_rows.append(\n",
    "                            {\"row\": row, \"error\": \"review_title too long\"}\n",
    "                        )\n",
    "                        continue\n",
    "\n",
    "                    # Handle review score\n",
    "                    try:\n",
    "                        review_score = float(row[\"overall\"])\n",
    "                    except:\n",
    "                        review_score = 0.0\n",
    "\n",
    "                    # Handle helpfulness rating\n",
    "                    try:\n",
    "                        rating_array = convert_value(row[\"helpful\"])\n",
    "                        helpfullness_rating = float(\n",
    "                            round(rating_array[0] / rating_array[1], 2)\n",
    "                        )\n",
    "                    except:\n",
    "                        helpfullness_rating = 0.0\n",
    "\n",
    "                    # Handle review date\n",
    "                    try:\n",
    "                        review_datetime = datetime.utcfromtimestamp(\n",
    "                            int(row[\"unixReviewTime\"])\n",
    "                        )\n",
    "                    except:\n",
    "                        review_datetime = \"1900-01-01 00:00:00\"\n",
    "\n",
    "                    # Add the transformed row\n",
    "                    transformed_rows.append(\n",
    "                        [\n",
    "                            reviewer_id,\n",
    "                            product_key,\n",
    "                            reviewer_name,\n",
    "                            helpfullness_rating,\n",
    "                            review_text,\n",
    "                            review_score,\n",
    "                            review_title,\n",
    "                            review_datetime,\n",
    "                        ]\n",
    "                    )\n",
    "\n",
    "                except Exception as e:\n",
    "                    failed_rows.append({\"row\": row, \"error\": str(e)})\n",
    "                    continue  # Skip this row and continue with others\n",
    "\n",
    "            if transformed_rows:\n",
    "                # Convert to CSV format (in-memory) for COPY\n",
    "                output = io.StringIO()\n",
    "                for row in transformed_rows:\n",
    "                    output.write(\"\\t\".join(map(str, row)) + \"\\n\")  # Tab-separated\n",
    "                output.seek(0)\n",
    "\n",
    "                try:\n",
    "                    cursor.copy_from(\n",
    "                        output,\n",
    "                        \"S1_Review\",\n",
    "                        sep=\"\\t\",\n",
    "                        columns=[\n",
    "                            \"R_Reviewer_Source_Key\",\n",
    "                            \"R_Product_Key\",\n",
    "                            \"R_Reviewer_Name\",\n",
    "                            \"R_Helpfulness_Rating\",\n",
    "                            \"R_Review_Text\",\n",
    "                            \"R_Review_Score\",\n",
    "                            \"R_Review_Title\",\n",
    "                            \"R_Review_DateTime\",\n",
    "                        ],\n",
    "                    )\n",
    "                    conn.commit()\n",
    "                    chunk_count += 1\n",
    "                    print(\n",
    "                        f\"Loaded chunk {chunk_count} ({len(transformed_rows)} records)\"\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    failed_rows.append({\"chunk_error\": str(e)})\n",
    "\n",
    "    # Log the failed rows into a JSON file after processing\n",
    "    if failed_rows:\n",
    "        with open(\"failed_rows.json\", \"w\", encoding=\"utf-8\") as jsonf:\n",
    "            json.dump(failed_rows, jsonf, indent=4)\n",
    "            print(f\"Logged {len(failed_rows)} failed rows to 'failed_rows.json'\")\n",
    "\n",
    "    print(\"Data ingestion complete.\")\n",
    "\n",
    "\n",
    "# Run the ingestion\n",
    "csvFilePath = r\"./metadata_category_clothing_shoes_and_jewelry_only.csv\"\n",
    "ingest_reviews(csvFilePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;241m0\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "print(0 / 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
